{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9496b36-a40b-467e-83aa-a29f5982cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pickle\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292d82c3-06bc-424c-ae8b-ab156c6dd794",
   "metadata": {},
   "source": [
    "**Load the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0191d61e-4fb9-4472-af70-851edb1d79b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 3072), (50000,), (10000, 3072), (10000,))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "    \n",
    "for i in range(1, 6):\n",
    "    dict = unpickle('data_batch_'+str(i))\n",
    "    x_data = dict[b'data']\n",
    "    y_data = np.array(dict[b'labels'])\n",
    "    if i == 1:\n",
    "        x_training = x_data\n",
    "        y_training = y_data\n",
    "    else:\n",
    "        x_training = np.concatenate((x_training, x_data))\n",
    "        y_training = np.concatenate((y_training, y_data))\n",
    "        \n",
    "dict = unpickle('test_batch')\n",
    "x_testing = dict[b'data'] \n",
    "y_testing = np.array(dict[b'labels'])\n",
    "\n",
    "x_training.shape, y_training.shape, x_testing.shape, y_testing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d71704f-f2d5-4f55-bffa-fd76e42a0dee",
   "metadata": {},
   "source": [
    "The image data needs to be normalised, the pixel values will range from 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a31ed7ea-46a6-46e4-ba2f-2b1b8e75ff20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training =x_training/255\n",
    "y_training = y_training\n",
    "x_testing = x_testing/255\n",
    "y_testing = y_testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285ea75-b961-45d3-939e-4dd099ee161e",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "2d059bab-88fe-435a-b034-01e551095a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_reshaped = x_training[0].reshape(3,32,32).transpose([ 1, 2, 0])\n",
    "x_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "56513a0a-c4df-4bc9-baf8-7dc8721c15ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2126c5e9f10>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (1, 1)) \n",
    "plt.imshow(x_train_reshaped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80513b83-ceeb-4dc6-9175-4662db1ce0a2",
   "metadata": {},
   "source": [
    "Each row of the sample CIFAR-10 Dataset is labelled according to the object in the picture, so classes will be defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "391867e7-03ec-44b7-8ead-48df150832a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \"Horse\", \"Ship\", \"Truck\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd965948-ad14-4096-b55d-0255f718bf88",
   "metadata": {},
   "source": [
    "y_training[0,:] returns 6, class_names[6] = \"Frog\"\n",
    "\n",
    "y_training[1,:] returns 9, class_names[9] = \"Truck\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "582ce661-c944-4e23-842c-01487b64ca9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Deer')"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (1, 1))\n",
    "plt.imshow(x_training[3].reshape(3,32,32).transpose([ 1, 2, 0]))\n",
    "plt.xlabel(class_names[y_training[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3b7c64-1671-4d0c-9b3f-e550ba4998d1",
   "metadata": {},
   "source": [
    "The unpickled data from the batch files is already flattened, so there is no need to reshape the data from 32x32x3 to 3072. A dataframe will be created to show the observations and features of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "e862f083-f814-4543-99b6-aba6e77df819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pixel_0</th>\n",
       "      <th>Pixel_1</th>\n",
       "      <th>Pixel_2</th>\n",
       "      <th>Pixel_3</th>\n",
       "      <th>Pixel_4</th>\n",
       "      <th>Pixel_5</th>\n",
       "      <th>Pixel_6</th>\n",
       "      <th>Pixel_7</th>\n",
       "      <th>Pixel_8</th>\n",
       "      <th>Pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Pixel_3063</th>\n",
       "      <th>Pixel_3064</th>\n",
       "      <th>Pixel_3065</th>\n",
       "      <th>Pixel_3066</th>\n",
       "      <th>Pixel_3067</th>\n",
       "      <th>Pixel_3068</th>\n",
       "      <th>Pixel_3069</th>\n",
       "      <th>Pixel_3070</th>\n",
       "      <th>Pixel_3071</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.196078</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.384314</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.568627</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227451</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>0.223529</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.603922</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.674510</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.435294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.396078</td>\n",
       "      <td>0.478431</td>\n",
       "      <td>0.521569</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.556863</td>\n",
       "      <td>0.564706</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.270588</td>\n",
       "      <td>0.258824</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.125490</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152941</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.172549</td>\n",
       "      <td>0.188235</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.145098</td>\n",
       "      <td>0.180392</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.345098</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.309804</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3073 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pixel_0   Pixel_1   Pixel_2   Pixel_3   Pixel_4   Pixel_5   Pixel_6  \\\n",
       "0  0.231373  0.168627  0.196078  0.266667  0.384314  0.466667  0.545098   \n",
       "1  0.603922  0.494118  0.411765  0.400000  0.490196  0.607843  0.674510   \n",
       "2  1.000000  0.992157  0.992157  0.992157  0.992157  0.992157  0.992157   \n",
       "3  0.109804  0.145098  0.149020  0.164706  0.172549  0.156863  0.156863   \n",
       "4  0.666667  0.658824  0.694118  0.717647  0.709804  0.694118  0.709804   \n",
       "\n",
       "    Pixel_7   Pixel_8   Pixel_9  ...  Pixel_3063  Pixel_3064  Pixel_3065  \\\n",
       "0  0.568627  0.584314  0.584314  ...    0.227451    0.254902    0.231373   \n",
       "1  0.705882  0.556863  0.435294  ...    0.164706    0.262745    0.396078   \n",
       "2  0.992157  0.992157  0.992157  ...    0.325490    0.313725    0.270588   \n",
       "3  0.094118  0.125490  0.168627  ...    0.152941    0.231373    0.164706   \n",
       "4  0.721569  0.741176  0.741176  ...    0.345098    0.333333    0.321569   \n",
       "\n",
       "   Pixel_3066  Pixel_3067  Pixel_3068  Pixel_3069  Pixel_3070  Pixel_3071  \\\n",
       "0    0.180392    0.223529    0.407843    0.549020    0.329412    0.282353   \n",
       "1    0.478431    0.521569    0.533333    0.545098    0.556863    0.564706   \n",
       "2    0.258824    0.282353    0.309804    0.325490    0.325490    0.329412   \n",
       "3    0.172549    0.188235    0.149020    0.109804    0.145098    0.180392   \n",
       "4    0.325490    0.309804    0.305882    0.321569    0.305882    0.313725   \n",
       "\n",
       "   Label  \n",
       "0      6  \n",
       "1      9  \n",
       "2      9  \n",
       "3      4  \n",
       "4      1  \n",
       "\n",
       "[5 rows x 3073 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = ['Pixel_' + str(i) for i in range((x_training).shape[1])]\n",
    "x_train_df = pd.DataFrame(x_training, columns = feature_columns)\n",
    "x_train_df['Label'] = y_training\n",
    "x_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c3fbc8-a78e-47c8-8177-978fc458e390",
   "metadata": {},
   "source": [
    "**Principle Component Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84192247-b5e4-4c7c-9033-df2285212b62",
   "metadata": {},
   "source": [
    "The image data (training and test sets) have to be reduced to 658, 217 and 99 features with the aim of improving training and computational efficiecy and model accuracy. A significant amount of the explained variance has to be captured to ensure that the model will be able to execute the classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "fc97ac58-ed77-4b2c-a8a0-656636dc9462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "      <th>PC_5</th>\n",
       "      <th>PC_6</th>\n",
       "      <th>PC_7</th>\n",
       "      <th>PC_8</th>\n",
       "      <th>PC_9</th>\n",
       "      <th>PC_10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC_650</th>\n",
       "      <th>PC_651</th>\n",
       "      <th>PC_652</th>\n",
       "      <th>PC_653</th>\n",
       "      <th>PC_654</th>\n",
       "      <th>PC_655</th>\n",
       "      <th>PC_656</th>\n",
       "      <th>PC_657</th>\n",
       "      <th>PC_658</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.401018</td>\n",
       "      <td>2.729039</td>\n",
       "      <td>1.501711</td>\n",
       "      <td>-2.953333</td>\n",
       "      <td>-4.452582</td>\n",
       "      <td>0.647150</td>\n",
       "      <td>0.568989</td>\n",
       "      <td>0.092877</td>\n",
       "      <td>3.451771</td>\n",
       "      <td>1.168442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038987</td>\n",
       "      <td>0.003489</td>\n",
       "      <td>0.104522</td>\n",
       "      <td>0.049940</td>\n",
       "      <td>-0.028230</td>\n",
       "      <td>0.045721</td>\n",
       "      <td>-0.042537</td>\n",
       "      <td>-0.027161</td>\n",
       "      <td>-0.168442</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829783</td>\n",
       "      <td>-0.949943</td>\n",
       "      <td>6.003753</td>\n",
       "      <td>1.504931</td>\n",
       "      <td>-1.368500</td>\n",
       "      <td>1.225687</td>\n",
       "      <td>0.606882</td>\n",
       "      <td>-0.523086</td>\n",
       "      <td>2.584150</td>\n",
       "      <td>2.565564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.146165</td>\n",
       "      <td>-0.170464</td>\n",
       "      <td>-0.231176</td>\n",
       "      <td>0.073827</td>\n",
       "      <td>-0.001975</td>\n",
       "      <td>0.071112</td>\n",
       "      <td>-0.040846</td>\n",
       "      <td>-0.056223</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.730200</td>\n",
       "      <td>-11.522102</td>\n",
       "      <td>-2.753621</td>\n",
       "      <td>2.333595</td>\n",
       "      <td>-1.584409</td>\n",
       "      <td>-2.272213</td>\n",
       "      <td>-0.610438</td>\n",
       "      <td>-1.361358</td>\n",
       "      <td>-0.730908</td>\n",
       "      <td>-1.125914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074948</td>\n",
       "      <td>-0.037555</td>\n",
       "      <td>-0.007621</td>\n",
       "      <td>0.044770</td>\n",
       "      <td>-0.080896</td>\n",
       "      <td>0.009134</td>\n",
       "      <td>-0.062690</td>\n",
       "      <td>-0.010992</td>\n",
       "      <td>-0.096811</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.347817</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>1.101019</td>\n",
       "      <td>-1.304540</td>\n",
       "      <td>-1.594870</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.232392</td>\n",
       "      <td>1.467262</td>\n",
       "      <td>-0.359152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047862</td>\n",
       "      <td>-0.006335</td>\n",
       "      <td>0.031149</td>\n",
       "      <td>0.091097</td>\n",
       "      <td>-0.002226</td>\n",
       "      <td>0.027292</td>\n",
       "      <td>-0.056197</td>\n",
       "      <td>0.053270</td>\n",
       "      <td>-0.005163</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.625651</td>\n",
       "      <td>-4.969240</td>\n",
       "      <td>1.034585</td>\n",
       "      <td>3.306459</td>\n",
       "      <td>1.261683</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>5.655493</td>\n",
       "      <td>1.426761</td>\n",
       "      <td>3.918136</td>\n",
       "      <td>-1.955221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065035</td>\n",
       "      <td>0.015517</td>\n",
       "      <td>-0.057229</td>\n",
       "      <td>0.023147</td>\n",
       "      <td>-0.013635</td>\n",
       "      <td>0.019209</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.089801</td>\n",
       "      <td>-0.088337</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 659 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC_1       PC_2      PC_3      PC_4      PC_5      PC_6      PC_7  \\\n",
       "0  -6.401018   2.729039  1.501711 -2.953333 -4.452582  0.647150  0.568989   \n",
       "1   0.829783  -0.949943  6.003753  1.504931 -1.368500  1.225687  0.606882   \n",
       "2   7.730200 -11.522102 -2.753621  2.333595 -1.584409 -2.272213 -0.610438   \n",
       "3 -10.347817   0.010738  1.101019 -1.304540 -1.594870  0.867600  0.194107   \n",
       "4  -2.625651  -4.969240  1.034585  3.306459  1.261683  0.031241  5.655493   \n",
       "\n",
       "       PC_8      PC_9     PC_10  ...    PC_650    PC_651    PC_652    PC_653  \\\n",
       "0  0.092877  3.451771  1.168442  ... -0.038987  0.003489  0.104522  0.049940   \n",
       "1 -0.523086  2.584150  2.565564  ...  0.003065  0.146165 -0.170464 -0.231176   \n",
       "2 -1.361358 -0.730908 -1.125914  ...  0.074948 -0.037555 -0.007621  0.044770   \n",
       "3  0.232392  1.467262 -0.359152  ... -0.047862 -0.006335  0.031149  0.091097   \n",
       "4  1.426761  3.918136 -1.955221  ...  0.065035  0.015517 -0.057229  0.023147   \n",
       "\n",
       "     PC_654    PC_655    PC_656    PC_657    PC_658  Label  \n",
       "0 -0.028230  0.045721 -0.042537 -0.027161 -0.168442      6  \n",
       "1  0.073827 -0.001975  0.071112 -0.040846 -0.056223      9  \n",
       "2 -0.080896  0.009134 -0.062690 -0.010992 -0.096811      9  \n",
       "3 -0.002226  0.027292 -0.056197  0.053270 -0.005163      4  \n",
       "4 -0.013635  0.019209  0.007496  0.089801 -0.088337      1  \n",
       "\n",
       "[5 rows x 659 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce image dataset to 658 features\n",
    "pca_658 = PCA(n_components = 658)\n",
    "pca_658_data = pca_658.fit_transform(x_train_df.iloc[:,:-1])\n",
    "pca_columns = ['PC_' + str(i+1) for i in range((pca_658_data).shape[1])]\n",
    "x_train_pca_658 = pd.DataFrame(data = pca_658_data, columns = pca_columns)\n",
    "x_train_pca_658['Label'] = y_training\n",
    "x_train_pca_658.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "71913eca-509b-45f6-ac60-3174aa1f4ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.0"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set explained variance:\n",
    "round(sum(pca_658.explained_variance_ratio_)*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "63b07705-30b1-4a76-b948-f53795bc02be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_658 = PCA(n_components = 658)\n",
    "pca_658_data = pca_658.fit_transform(x_training)\n",
    "x_train_658 = pca_658.transform(x_training)\n",
    "x_test_658 = pca_658.transform(x_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "609c083e-1256-4796-ae67-f7bcc0839220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "      <th>PC_5</th>\n",
       "      <th>PC_6</th>\n",
       "      <th>PC_7</th>\n",
       "      <th>PC_8</th>\n",
       "      <th>PC_9</th>\n",
       "      <th>PC_10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC_209</th>\n",
       "      <th>PC_210</th>\n",
       "      <th>PC_211</th>\n",
       "      <th>PC_212</th>\n",
       "      <th>PC_213</th>\n",
       "      <th>PC_214</th>\n",
       "      <th>PC_215</th>\n",
       "      <th>PC_216</th>\n",
       "      <th>PC_217</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.401018</td>\n",
       "      <td>2.729039</td>\n",
       "      <td>1.501711</td>\n",
       "      <td>-2.953333</td>\n",
       "      <td>-4.452582</td>\n",
       "      <td>0.647150</td>\n",
       "      <td>0.568989</td>\n",
       "      <td>0.092877</td>\n",
       "      <td>3.451771</td>\n",
       "      <td>1.168442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398247</td>\n",
       "      <td>0.115541</td>\n",
       "      <td>-0.325964</td>\n",
       "      <td>-0.010171</td>\n",
       "      <td>0.069117</td>\n",
       "      <td>0.126900</td>\n",
       "      <td>0.150207</td>\n",
       "      <td>-0.156966</td>\n",
       "      <td>0.052944</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829783</td>\n",
       "      <td>-0.949943</td>\n",
       "      <td>6.003753</td>\n",
       "      <td>1.504931</td>\n",
       "      <td>-1.368500</td>\n",
       "      <td>1.225687</td>\n",
       "      <td>0.606882</td>\n",
       "      <td>-0.523086</td>\n",
       "      <td>2.584150</td>\n",
       "      <td>2.565564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087680</td>\n",
       "      <td>0.337429</td>\n",
       "      <td>0.827285</td>\n",
       "      <td>0.294114</td>\n",
       "      <td>-0.312825</td>\n",
       "      <td>0.389747</td>\n",
       "      <td>-0.193923</td>\n",
       "      <td>-0.369314</td>\n",
       "      <td>-0.009956</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.730200</td>\n",
       "      <td>-11.522102</td>\n",
       "      <td>-2.753621</td>\n",
       "      <td>2.333595</td>\n",
       "      <td>-1.584409</td>\n",
       "      <td>-2.272213</td>\n",
       "      <td>-0.610438</td>\n",
       "      <td>-1.361358</td>\n",
       "      <td>-0.730908</td>\n",
       "      <td>-1.125914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089563</td>\n",
       "      <td>-0.306690</td>\n",
       "      <td>0.148452</td>\n",
       "      <td>-0.292213</td>\n",
       "      <td>0.283477</td>\n",
       "      <td>0.225568</td>\n",
       "      <td>-0.131022</td>\n",
       "      <td>0.077934</td>\n",
       "      <td>0.299069</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.347817</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>1.101019</td>\n",
       "      <td>-1.304540</td>\n",
       "      <td>-1.594870</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.232392</td>\n",
       "      <td>1.467262</td>\n",
       "      <td>-0.359152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060347</td>\n",
       "      <td>0.192046</td>\n",
       "      <td>-0.112919</td>\n",
       "      <td>-0.302219</td>\n",
       "      <td>0.109766</td>\n",
       "      <td>-0.079465</td>\n",
       "      <td>0.085278</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.053435</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.625651</td>\n",
       "      <td>-4.969240</td>\n",
       "      <td>1.034585</td>\n",
       "      <td>3.306459</td>\n",
       "      <td>1.261683</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>5.655493</td>\n",
       "      <td>1.426761</td>\n",
       "      <td>3.918136</td>\n",
       "      <td>-1.955221</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.496169</td>\n",
       "      <td>-0.038941</td>\n",
       "      <td>0.180581</td>\n",
       "      <td>-0.009668</td>\n",
       "      <td>0.088189</td>\n",
       "      <td>-0.096412</td>\n",
       "      <td>-0.066690</td>\n",
       "      <td>-0.248180</td>\n",
       "      <td>0.210985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 218 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC_1       PC_2      PC_3      PC_4      PC_5      PC_6      PC_7  \\\n",
       "0  -6.401018   2.729039  1.501711 -2.953333 -4.452582  0.647150  0.568989   \n",
       "1   0.829783  -0.949943  6.003753  1.504931 -1.368500  1.225687  0.606882   \n",
       "2   7.730200 -11.522102 -2.753621  2.333595 -1.584409 -2.272213 -0.610438   \n",
       "3 -10.347817   0.010738  1.101019 -1.304540 -1.594870  0.867600  0.194107   \n",
       "4  -2.625651  -4.969240  1.034585  3.306459  1.261683  0.031241  5.655493   \n",
       "\n",
       "       PC_8      PC_9     PC_10  ...    PC_209    PC_210    PC_211    PC_212  \\\n",
       "0  0.092877  3.451771  1.168442  ...  0.398247  0.115541 -0.325964 -0.010171   \n",
       "1 -0.523086  2.584150  2.565564  ...  0.087680  0.337429  0.827285  0.294114   \n",
       "2 -1.361358 -0.730908 -1.125914  ...  0.089563 -0.306690  0.148452 -0.292213   \n",
       "3  0.232392  1.467262 -0.359152  ... -0.060347  0.192046 -0.112919 -0.302219   \n",
       "4  1.426761  3.918136 -1.955221  ... -0.496169 -0.038941  0.180581 -0.009668   \n",
       "\n",
       "     PC_213    PC_214    PC_215    PC_216    PC_217  Label  \n",
       "0  0.069117  0.126900  0.150207 -0.156966  0.052944      6  \n",
       "1 -0.312825  0.389747 -0.193923 -0.369314 -0.009956      9  \n",
       "2  0.283477  0.225568 -0.131022  0.077934  0.299069      9  \n",
       "3  0.109766 -0.079465  0.085278  0.069006  0.053435      4  \n",
       "4  0.088189 -0.096412 -0.066690 -0.248180  0.210985      1  \n",
       "\n",
       "[5 rows x 218 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce image dataset to 217 features\n",
    "pca_217 = PCA(n_components = 217)\n",
    "pca_217_data = pca_217.fit_transform(x_train_df.iloc[:,:-1])\n",
    "pca_columns = ['PC_' + str(i+1) for i in range((pca_217_data).shape[1])]\n",
    "x_train_pca_217 = pd.DataFrame(data = pca_217_data, columns = pca_columns)\n",
    "x_train_pca_217['Label'] = y_training\n",
    "x_train_pca_217.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0f3309ea-ed7b-4bbd-b4fe-d3d3a81d0676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set explained variance:\n",
    "round(sum(pca_217.explained_variance_ratio_)*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "76cc21db-fa0f-4c5a-847a-ed6ee64cd8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_217 = PCA(n_components = 217)\n",
    "pca_217_data = pca_217.fit_transform(x_training)\n",
    "x_train_217 = pca_217.transform(x_training)\n",
    "x_test_217 = pca_217.transform(x_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "ce9200d2-538e-48b0-829f-48b3abc21870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_1</th>\n",
       "      <th>PC_2</th>\n",
       "      <th>PC_3</th>\n",
       "      <th>PC_4</th>\n",
       "      <th>PC_5</th>\n",
       "      <th>PC_6</th>\n",
       "      <th>PC_7</th>\n",
       "      <th>PC_8</th>\n",
       "      <th>PC_9</th>\n",
       "      <th>PC_10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC_91</th>\n",
       "      <th>PC_92</th>\n",
       "      <th>PC_93</th>\n",
       "      <th>PC_94</th>\n",
       "      <th>PC_95</th>\n",
       "      <th>PC_96</th>\n",
       "      <th>PC_97</th>\n",
       "      <th>PC_98</th>\n",
       "      <th>PC_99</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.401018</td>\n",
       "      <td>2.729039</td>\n",
       "      <td>1.501711</td>\n",
       "      <td>-2.953333</td>\n",
       "      <td>-4.452582</td>\n",
       "      <td>0.647150</td>\n",
       "      <td>0.568989</td>\n",
       "      <td>0.092877</td>\n",
       "      <td>3.451771</td>\n",
       "      <td>1.168442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702755</td>\n",
       "      <td>-0.290031</td>\n",
       "      <td>0.193866</td>\n",
       "      <td>-0.752544</td>\n",
       "      <td>0.057862</td>\n",
       "      <td>-0.780648</td>\n",
       "      <td>-0.158463</td>\n",
       "      <td>-0.132501</td>\n",
       "      <td>0.305982</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.829783</td>\n",
       "      <td>-0.949943</td>\n",
       "      <td>6.003753</td>\n",
       "      <td>1.504931</td>\n",
       "      <td>-1.368500</td>\n",
       "      <td>1.225687</td>\n",
       "      <td>0.606882</td>\n",
       "      <td>-0.523086</td>\n",
       "      <td>2.584150</td>\n",
       "      <td>2.565564</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.466515</td>\n",
       "      <td>-0.020602</td>\n",
       "      <td>-0.296881</td>\n",
       "      <td>0.285077</td>\n",
       "      <td>0.446126</td>\n",
       "      <td>-0.458715</td>\n",
       "      <td>1.114973</td>\n",
       "      <td>0.051358</td>\n",
       "      <td>0.144102</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.730200</td>\n",
       "      <td>-11.522102</td>\n",
       "      <td>-2.753621</td>\n",
       "      <td>2.333595</td>\n",
       "      <td>-1.584409</td>\n",
       "      <td>-2.272213</td>\n",
       "      <td>-0.610438</td>\n",
       "      <td>-1.361358</td>\n",
       "      <td>-0.730908</td>\n",
       "      <td>-1.125914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381058</td>\n",
       "      <td>-0.334499</td>\n",
       "      <td>-0.106446</td>\n",
       "      <td>0.401481</td>\n",
       "      <td>0.576968</td>\n",
       "      <td>0.634195</td>\n",
       "      <td>-0.315374</td>\n",
       "      <td>-0.180395</td>\n",
       "      <td>0.432708</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-10.347817</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>1.101019</td>\n",
       "      <td>-1.304540</td>\n",
       "      <td>-1.594870</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.194107</td>\n",
       "      <td>0.232392</td>\n",
       "      <td>1.467262</td>\n",
       "      <td>-0.359152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157946</td>\n",
       "      <td>0.126818</td>\n",
       "      <td>-0.062142</td>\n",
       "      <td>-0.075616</td>\n",
       "      <td>0.228881</td>\n",
       "      <td>0.285584</td>\n",
       "      <td>-0.305017</td>\n",
       "      <td>0.057421</td>\n",
       "      <td>-0.255198</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.625651</td>\n",
       "      <td>-4.969240</td>\n",
       "      <td>1.034585</td>\n",
       "      <td>3.306459</td>\n",
       "      <td>1.261683</td>\n",
       "      <td>0.031241</td>\n",
       "      <td>5.655493</td>\n",
       "      <td>1.426761</td>\n",
       "      <td>3.918136</td>\n",
       "      <td>-1.955221</td>\n",
       "      <td>...</td>\n",
       "      <td>0.664295</td>\n",
       "      <td>-0.677702</td>\n",
       "      <td>-0.170580</td>\n",
       "      <td>-0.033824</td>\n",
       "      <td>-0.383039</td>\n",
       "      <td>-0.017818</td>\n",
       "      <td>-0.226585</td>\n",
       "      <td>-0.297569</td>\n",
       "      <td>-0.216790</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC_1       PC_2      PC_3      PC_4      PC_5      PC_6      PC_7  \\\n",
       "0  -6.401018   2.729039  1.501711 -2.953333 -4.452582  0.647150  0.568989   \n",
       "1   0.829783  -0.949943  6.003753  1.504931 -1.368500  1.225687  0.606882   \n",
       "2   7.730200 -11.522102 -2.753621  2.333595 -1.584409 -2.272213 -0.610438   \n",
       "3 -10.347817   0.010738  1.101019 -1.304540 -1.594870  0.867600  0.194107   \n",
       "4  -2.625651  -4.969240  1.034585  3.306459  1.261683  0.031241  5.655493   \n",
       "\n",
       "       PC_8      PC_9     PC_10  ...     PC_91     PC_92     PC_93     PC_94  \\\n",
       "0  0.092877  3.451771  1.168442  ...  0.702755 -0.290031  0.193866 -0.752544   \n",
       "1 -0.523086  2.584150  2.565564  ... -0.466515 -0.020602 -0.296881  0.285077   \n",
       "2 -1.361358 -0.730908 -1.125914  ...  0.381058 -0.334499 -0.106446  0.401481   \n",
       "3  0.232392  1.467262 -0.359152  ... -0.157946  0.126818 -0.062142 -0.075616   \n",
       "4  1.426761  3.918136 -1.955221  ...  0.664295 -0.677702 -0.170580 -0.033824   \n",
       "\n",
       "      PC_95     PC_96     PC_97     PC_98     PC_99  Label  \n",
       "0  0.057862 -0.780648 -0.158463 -0.132501  0.305982      6  \n",
       "1  0.446126 -0.458715  1.114973  0.051358  0.144102      9  \n",
       "2  0.576968  0.634195 -0.315374 -0.180395  0.432708      9  \n",
       "3  0.228881  0.285584 -0.305017  0.057421 -0.255198      4  \n",
       "4 -0.383039 -0.017818 -0.226585 -0.297569 -0.216790      1  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reduce image dataset to 99 features\n",
    "pca_99 = PCA(n_components = 99)\n",
    "pca_99_data = pca_99.fit_transform(x_train_df.iloc[:,:-1])\n",
    "pca_columns = ['PC_' + str(i+1) for i in range((pca_99_data).shape[1])]\n",
    "x_train_pca_99 = pd.DataFrame(data = pca_99_data, columns = pca_columns)\n",
    "x_train_pca_99['Label'] = y_training\n",
    "x_train_pca_99.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "37710af3-85b1-4051-a995-3906ba3f7c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.0"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training set explained variance:\n",
    "round(sum(pca_99.explained_variance_ratio_)*100, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "41af0963-5bcc-47c7-b72e-d0fa8a9389b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_99 = PCA(n_components = 99)\n",
    "pca_99_data = pca_99.fit_transform(x_training)\n",
    "x_train_99 = pca_99.transform(x_training)\n",
    "x_test_99 = pca_99.transform(x_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bd98d7-1940-4b1c-876d-a549e42fa663",
   "metadata": {},
   "source": [
    "Reducing the training set whcih contains 3072 features to 658 features using PCA ensures that 99% of the variance is explained, reducing to 217 results in 95% explained variance and 99 features explains 90% of the variance. Logistic Regression and Neural Network models will be developed and trained using the original data set consisting of 3072 features as well as the reduced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecddd58-d5da-4daa-9dfe-f9cffe385ce2",
   "metadata": {},
   "source": [
    "**Logistic Regression Model Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9c9992-9322-4db9-a4e6-0ce01f33b32a",
   "metadata": {},
   "source": [
    "The Multinomial Logistic Regression Model implemented comprises of a C value (Strength of regularization) of 50 which was obtained experimentally, L1 regularisation penalty was used as well as a Stochastic Average Gradient Algorithm for updating the model's parameters. A tolerance of 0.1 was chosen for the Logistic Regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64ed75c-a9f7-453e-aca9-28040fff1133",
   "metadata": {},
   "source": [
    "**Logistic Regression using 3072 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5b848fea-0fc0-4bd4-8c5e-fe6d6e760e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_3072 = LogisticRegression(C = 50.0, \n",
    "                                              penalty=\"l1\", \n",
    "                                              solver=\"saga\", \n",
    "                                              tol=0.1\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "faf1e7a5-edf1-45de-be3c-13248df9614b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-29 {color: black;background-color: white;}#sk-container-id-29 pre{padding: 0;}#sk-container-id-29 div.sk-toggleable {background-color: white;}#sk-container-id-29 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-29 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-29 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-29 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-29 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-29 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-29 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-29 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-29 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-29 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-29 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-29 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-29 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-29 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-29 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-29 div.sk-item {position: relative;z-index: 1;}#sk-container-id-29 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-29 div.sk-item::before, #sk-container-id-29 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-29 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-29 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-29 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-29 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-29 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-29 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-29 div.sk-label-container {text-align: center;}#sk-container-id-29 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-29 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-29\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=50.0, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" checked><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=50.0, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=50.0, penalty='l1', solver='saga', tol=0.1)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_3072.fit(x_train_3072, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "c5f0eb48-f0fc-42b6-8f4d-bae382dbe583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43982"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_3072.score(x_train_3072, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "955b4e51-0b18-465b-b171-b5bbf3d7563a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.414"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_3072.score(x_test_3072, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81984de9-03be-4b80-877b-0e189dd0b0c7",
   "metadata": {},
   "source": [
    "**Logistic Regression using 658 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "12febec0-8edd-4dbb-9ec8-96d2927664f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_658 = LogisticRegression(C = 50.0, \n",
    "                                              penalty=\"l1\", \n",
    "                                              solver=\"saga\", \n",
    "                                              tol=0.1\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e329cc10-c055-4876-9797-6ba1cc36e7c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-30 {color: black;background-color: white;}#sk-container-id-30 pre{padding: 0;}#sk-container-id-30 div.sk-toggleable {background-color: white;}#sk-container-id-30 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-30 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-30 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-30 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-30 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-30 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-30 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-30 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-30 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-30 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-30 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-30 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-30 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-30 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-30 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-30 div.sk-item {position: relative;z-index: 1;}#sk-container-id-30 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-30 div.sk-item::before, #sk-container-id-30 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-30 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-30 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-30 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-30 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-30 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-30 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-30 div.sk-label-container {text-align: center;}#sk-container-id-30 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-30 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-30\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=50.0, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" checked><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=50.0, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=50.0, penalty='l1', solver='saga', tol=0.1)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_658.fit(x_train_658, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "141ce4cb-8b1d-448b-b395-834a6119ccca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44134"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_658.score(x_train_658, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f9236439-1643-4d3d-924f-68d5f2b4ee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4084"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_658.score(x_test_658, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3efe33-023e-48c1-925b-2d1673db8057",
   "metadata": {},
   "source": [
    "**Logistic Regression using 217 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "f20d0130-e378-4223-ad73-a1c2b0f47f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_217 = LogisticRegression(C = 50.0,\n",
    "                                              penalty=\"l1\", \n",
    "                                              solver=\"saga\", \n",
    "                                              tol=0.01\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bb0628c9-f24d-4b06-a3bd-8b692df468b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-31 {color: black;background-color: white;}#sk-container-id-31 pre{padding: 0;}#sk-container-id-31 div.sk-toggleable {background-color: white;}#sk-container-id-31 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-31 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-31 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-31 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-31 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-31 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-31 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-31 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-31 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-31 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-31 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-31 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-31 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-31 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-31 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-31 div.sk-item {position: relative;z-index: 1;}#sk-container-id-31 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-31 div.sk-item::before, #sk-container-id-31 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-31 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-31 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-31 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-31 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-31 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-31 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-31 div.sk-label-container {text-align: center;}#sk-container-id-31 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-31 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-31\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=50.0, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" checked><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=50.0, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=50.0, penalty='l1', solver='saga', tol=0.01)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_217.fit(x_train_217, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "65bed5ed-4be8-45e3-9021-1842ec3de657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42816"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_217.score(x_train_217, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "5d1c4576-0210-491e-8d5b-107369d56377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4057"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_217.score(x_test_217, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c4a6e-0914-44b6-bedd-c6118e897eee",
   "metadata": {},
   "source": [
    "**Logistic Regression using 99 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "005ef6ca-e81d-43c4-8ac2-e970bedadb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_99 = LogisticRegression(C = 50.0,\n",
    "                                              penalty=\"l1\", \n",
    "                                              solver=\"saga\", \n",
    "                                              tol=0.01\n",
    "                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "977f250e-9e93-4a4d-ac20-14b96c00e7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-32 {color: black;background-color: white;}#sk-container-id-32 pre{padding: 0;}#sk-container-id-32 div.sk-toggleable {background-color: white;}#sk-container-id-32 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-32 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-32 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-32 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-32 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-32 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-32 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-32 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-32 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-32 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-32 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-32 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-32 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-32 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-32 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-32 div.sk-item {position: relative;z-index: 1;}#sk-container-id-32 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-32 div.sk-item::before, #sk-container-id-32 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-32 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-32 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-32 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-32 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-32 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-32 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-32 div.sk-label-container {text-align: center;}#sk-container-id-32 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-32 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-32\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=50.0, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" checked><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=50.0, penalty=&#x27;l1&#x27;, solver=&#x27;saga&#x27;, tol=0.01)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=50.0, penalty='l1', solver='saga', tol=0.01)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_99.fit(x_train_99, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "2350ee77-66ee-40b0-8bd1-84490ff809c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40492"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_99.score(x_train_99, y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "a0a3ec68-411c-4e95-9ba7-243b01e36375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4024"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_99.score(x_test_99, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca775d1a-0d7a-4d65-8a66-a3c25db4e6ef",
   "metadata": {},
   "source": [
    "Fitting a Logistic Regression model with 3072 features takes 79 seconds to excecute, a training accuracy of 44.0% was achieved and a testing score of 41.4%. Reducing the features to 658 resulted in a fitting execution time of 10 seconds and a training and testing accuracy of 44.1% and 40.8% respectively. A model with 217 features resulted in a fitting execution time of 6 seconds and a training and testing accuracy of 42.8% and 40.6% respectively. 99 Features expectedly has the shortest fitting execution time of 2 seconds, however the accuracy of both the training and testing sets decreased to 40.9% and 40.2%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497584a8-f3ba-4f45-8185-70df38cb22e9",
   "metadata": {},
   "source": [
    "**Neural Network Model Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cacc29c-876b-4c75-97da-7fa94a7424cf",
   "metadata": {},
   "source": [
    "The Neural Networks to be implemented will consist of an input layer, 2 hidden laters using the Rectified Linear Unit (Relu) activation function and the hidden layers will consist of 128 and 64 neurons respectively. The output layer will cosist of 10 neurons since the problem is a 10-class classification problem, the activation function used for the output is the Soft Maximum (Softmax), it was preferred because it achived slightly better performance than the Relu. Overfitting is prevented by adding dropouts at the output of each hidden layer to reduce overfitting, the models used here will have 20% of the neurons randomly dropping out. The model uses Sparse Categorical Cross Entropy as a loss function and Adaptive Moment Estimation (Adam) as the optmizer with a learning rate of 0.001.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec5ad4f-104a-4c13-8c0d-53849c925c36",
   "metadata": {},
   "source": [
    "Neural Network using 3072 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "16e47b43-4495-49e2-aca7-ff70aabc74b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_57\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_57\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_164 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">393,344</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_165 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_166 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_164 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m393,344\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_103 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_165 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_104 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_166 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">402,250</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m402,250\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">402,250</span> (1.53 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m402,250\u001b[0m (1.53 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network_3072 = models.Sequential([\n",
    "    layers.InputLayer(shape = ([3072])), \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')    \n",
    "])\n",
    "neural_network_3072.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "34c702bd-c6ef-4111-8110-57129418510e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.4759 - loss: 1.4616\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4858 - loss: 1.4450\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4874 - loss: 1.4359\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4843 - loss: 1.4392\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4810 - loss: 1.4409\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4867 - loss: 1.4376\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4829 - loss: 1.4364\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4866 - loss: 1.4343\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4870 - loss: 1.4292\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4922 - loss: 1.4182\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4922 - loss: 1.4230\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4880 - loss: 1.4229\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4924 - loss: 1.4223\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4921 - loss: 1.4093\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4941 - loss: 1.4143\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4941 - loss: 1.4083\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4898 - loss: 1.4201\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4869 - loss: 1.4148\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4958 - loss: 1.4053\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4965 - loss: 1.4027\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4956 - loss: 1.4035\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4999 - loss: 1.3958\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4975 - loss: 1.4056\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4933 - loss: 1.4039\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4993 - loss: 1.3978\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4956 - loss: 1.4006\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5007 - loss: 1.3937\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4995 - loss: 1.3836\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5031 - loss: 1.3843\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4977 - loss: 1.3979\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5030 - loss: 1.3874\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5022 - loss: 1.3917\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.4995 - loss: 1.3983\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5047 - loss: 1.3859\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5008 - loss: 1.3968\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4998 - loss: 1.3836\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5059 - loss: 1.3789\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5007 - loss: 1.3749\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5078 - loss: 1.3714\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5043 - loss: 1.3715\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5033 - loss: 1.3826\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5062 - loss: 1.3757\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5090 - loss: 1.3694\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5050 - loss: 1.3743\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5042 - loss: 1.3761\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5107 - loss: 1.3591\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5114 - loss: 1.3670\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.5119 - loss: 1.3641\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5086 - loss: 1.3660\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5119 - loss: 1.3640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x21307197d90>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network_3072.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "                       optimizer = tf.keras.optimizers.Adam(0.001), \n",
    "                       metrics = [\"accuracy\"])\n",
    "\n",
    "neural_network_3072.fit(x_training, y_training, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "bc64ad1f-88dc-46ac-97ea-fe4f68e598f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.5195 - loss: 1.3597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3687028884887695, 0.5127999782562256]"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#neural_network_3072.evaluate(x_test_3072, y_testing)\n",
    "neural_network_3072.evaluate(x_testing, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22db74d-3854-4e59-b6ee-e7a182a3d968",
   "metadata": {},
   "source": [
    "**Neural Network using 658 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "76293140-5912-42d0-b516-027d73765fc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_61\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_61\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_178 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">84,352</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_112 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_179 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_113 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_180 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_178 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m84,352\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_112 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_179 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_113 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_180 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,258</span> (364.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m93,258\u001b[0m (364.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">93,258</span> (364.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m93,258\u001b[0m (364.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network_658 = models.Sequential([\n",
    "    layers.InputLayer(shape = ([658])),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')    \n",
    "])\n",
    "neural_network_658.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "cb598f29-076b-41f9-a1fe-fa122951ca4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.3114 - loss: 1.9276\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4660 - loss: 1.5213\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5114 - loss: 1.3948\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5346 - loss: 1.3061\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5630 - loss: 1.2358\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5795 - loss: 1.1752\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5919 - loss: 1.1426\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6059 - loss: 1.1057\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6201 - loss: 1.0599\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6202 - loss: 1.0519\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6341 - loss: 1.0160\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6460 - loss: 0.9872\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6487 - loss: 0.9761\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6561 - loss: 0.9583\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6597 - loss: 0.9337\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6625 - loss: 0.9310\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6697 - loss: 0.9139\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6783 - loss: 0.8955\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6805 - loss: 0.8831\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6875 - loss: 0.8719\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6852 - loss: 0.8674\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6930 - loss: 0.8501\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6966 - loss: 0.8363\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6994 - loss: 0.8305\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7025 - loss: 0.8262\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7055 - loss: 0.8091\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7082 - loss: 0.8050\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7137 - loss: 0.7912\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7160 - loss: 0.7854\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7171 - loss: 0.7879\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7169 - loss: 0.7773\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7260 - loss: 0.7587\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7227 - loss: 0.7636\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7281 - loss: 0.7483\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7279 - loss: 0.7461\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7290 - loss: 0.7538\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7333 - loss: 0.7384\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7361 - loss: 0.7301\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7347 - loss: 0.7335\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.7206\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7466 - loss: 0.7093\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7405 - loss: 0.7116\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7401 - loss: 0.7180\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7497 - loss: 0.6948\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7430 - loss: 0.7096\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7527 - loss: 0.6964\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7487 - loss: 0.6937\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7541 - loss: 0.6803\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7581 - loss: 0.6777\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7575 - loss: 0.6807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x213a7d25190>"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network_658.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "                       optimizer = tf.keras.optimizers.Adam(0.001), \n",
    "                       metrics = [\"accuracy\"])\n",
    "\n",
    "neural_network_658.fit(x_train_658, y_training, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "db6e964c-3c5d-42a9-9364-9dc3fe828218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.4945 - loss: 1.7051\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6944375038146973, 0.4966000020503998]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network_658.evaluate(x_test_658, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13423cd-c65a-4b4b-8afb-579c626e921b",
   "metadata": {},
   "source": [
    "**Neural Network using 217 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f4ba6e5b-94ed-49a2-b4cc-e042261e59ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_58\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_58\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_169 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">27,904</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_170 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_171 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_169 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m27,904\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_106 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_170 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_107 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_171 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,810</span> (143.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,810\u001b[0m (143.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,810</span> (143.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,810\u001b[0m (143.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network_217 = models.Sequential([\n",
    "    layers.InputLayer(shape = ([217])),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')    \n",
    "])\n",
    "neural_network_217.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "72ed3831-33ed-44e7-b7f0-6affa5864017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6312 - loss: 1.0173\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 960us/step - accuracy: 0.6329 - loss: 1.0164\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987us/step - accuracy: 0.6252 - loss: 1.0231\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964us/step - accuracy: 0.6299 - loss: 1.0329\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6300 - loss: 1.0154\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 977us/step - accuracy: 0.6322 - loss: 1.0098\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 957us/step - accuracy: 0.6352 - loss: 1.0144\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6365 - loss: 1.0044\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 995us/step - accuracy: 0.6359 - loss: 1.0083\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 0.6324 - loss: 1.0035\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step - accuracy: 0.6349 - loss: 1.0152\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985us/step - accuracy: 0.6369 - loss: 1.0033\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 0.6383 - loss: 1.0037\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 950us/step - accuracy: 0.6377 - loss: 0.9997\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987us/step - accuracy: 0.6378 - loss: 0.9965\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6388 - loss: 1.0001\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 977us/step - accuracy: 0.6366 - loss: 0.9966\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 976us/step - accuracy: 0.6365 - loss: 1.0023\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 990us/step - accuracy: 0.6327 - loss: 1.0036\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 958us/step - accuracy: 0.6420 - loss: 0.9908\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step - accuracy: 0.6364 - loss: 1.0009\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6346 - loss: 1.0067\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985us/step - accuracy: 0.6392 - loss: 0.9996\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 991us/step - accuracy: 0.6398 - loss: 0.9945\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 976us/step - accuracy: 0.6426 - loss: 0.9897\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6426 - loss: 0.9900\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6409 - loss: 0.9923\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993us/step - accuracy: 0.6418 - loss: 0.9890\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 978us/step - accuracy: 0.6470 - loss: 0.9781\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987us/step - accuracy: 0.6366 - loss: 1.0005\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 971us/step - accuracy: 0.6432 - loss: 0.9817\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 985us/step - accuracy: 0.6429 - loss: 0.9799\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step - accuracy: 0.6448 - loss: 0.9835\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 998us/step - accuracy: 0.6416 - loss: 0.9854\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6433 - loss: 0.9824\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 996us/step - accuracy: 0.6421 - loss: 0.9918\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6387 - loss: 0.9908\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6470 - loss: 0.9755\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6452 - loss: 0.9788\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987us/step - accuracy: 0.6430 - loss: 0.9841\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6423 - loss: 0.9875\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 948us/step - accuracy: 0.6456 - loss: 0.9735\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 969us/step - accuracy: 0.6407 - loss: 0.9782\n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 976us/step - accuracy: 0.6491 - loss: 0.9690\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 983us/step - accuracy: 0.6460 - loss: 0.9742\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 967us/step - accuracy: 0.6488 - loss: 0.9759\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6457 - loss: 0.9762\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 987us/step - accuracy: 0.6462 - loss: 0.9713\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 991us/step - accuracy: 0.6521 - loss: 0.9675\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 975us/step - accuracy: 0.6487 - loss: 0.9747\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2127803b090>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network_217.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "                       optimizer = tf.keras.optimizers.Adam(0.001), \n",
    "                       metrics = [\"accuracy\"])\n",
    "\n",
    "neural_network_217.fit(x_train_217, y_training, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "61b16556-f657-408c-9935-f81fbcd6f75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.5310 - loss: 1.3547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3652251958847046, 0.5303999781608582]"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network_217.evaluate(x_test_217, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c295b7-7606-4eeb-b3ad-0785c2fc1773",
   "metadata": {},
   "source": [
    "**Neural Network using 99 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "56b3e8be-2d63-43d2-8cbb-6462b9a202d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_60\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_60\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_175 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_176 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_177 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense_175 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m12,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_110 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_176 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_111 (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_177 (\u001b[38;5;33mDense\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,706</span> (84.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,706\u001b[0m (84.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,706</span> (84.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,706\u001b[0m (84.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network_99 = models.Sequential([\n",
    "    layers.InputLayer(shape = ([99])),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(10, activation='softmax')    \n",
    "])\n",
    "neural_network_99.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "b1510246-91df-40e3-a8c4-db5da83b988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 973us/step - accuracy: 0.5720 - loss: 1.1849\n",
      "Epoch 2/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 935us/step - accuracy: 0.5749 - loss: 1.1860\n",
      "Epoch 3/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 993us/step - accuracy: 0.5756 - loss: 1.1771\n",
      "Epoch 4/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 941us/step - accuracy: 0.5740 - loss: 1.1861\n",
      "Epoch 5/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 981us/step - accuracy: 0.5752 - loss: 1.1764\n",
      "Epoch 6/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.5751 - loss: 1.1785\n",
      "Epoch 7/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 945us/step - accuracy: 0.5766 - loss: 1.1684\n",
      "Epoch 8/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 943us/step - accuracy: 0.5780 - loss: 1.1682\n",
      "Epoch 9/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.5768 - loss: 1.1770\n",
      "Epoch 10/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934us/step - accuracy: 0.5762 - loss: 1.1774\n",
      "Epoch 11/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.5700 - loss: 1.1808\n",
      "Epoch 12/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 949us/step - accuracy: 0.5788 - loss: 1.1658\n",
      "Epoch 13/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.5722 - loss: 1.1663\n",
      "Epoch 14/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 927us/step - accuracy: 0.5782 - loss: 1.1702\n",
      "Epoch 15/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 937us/step - accuracy: 0.5806 - loss: 1.1621\n",
      "Epoch 16/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 946us/step - accuracy: 0.5817 - loss: 1.1671\n",
      "Epoch 17/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.5743 - loss: 1.1796\n",
      "Epoch 18/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 914us/step - accuracy: 0.5771 - loss: 1.1719\n",
      "Epoch 19/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 917us/step - accuracy: 0.5779 - loss: 1.1654\n",
      "Epoch 20/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 931us/step - accuracy: 0.5733 - loss: 1.1763\n",
      "Epoch 21/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 0.5770 - loss: 1.1707\n",
      "Epoch 22/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.5830 - loss: 1.1548\n",
      "Epoch 23/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 0.5805 - loss: 1.1579\n",
      "Epoch 24/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step - accuracy: 0.5802 - loss: 1.1604\n",
      "Epoch 25/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.5833 - loss: 1.1578\n",
      "Epoch 26/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 956us/step - accuracy: 0.5816 - loss: 1.1534\n",
      "Epoch 27/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.5760 - loss: 1.1594\n",
      "Epoch 28/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 948us/step - accuracy: 0.5795 - loss: 1.1582\n",
      "Epoch 29/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 961us/step - accuracy: 0.5776 - loss: 1.1613\n",
      "Epoch 30/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.5797 - loss: 1.1663\n",
      "Epoch 31/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 925us/step - accuracy: 0.5799 - loss: 1.1589\n",
      "Epoch 32/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 945us/step - accuracy: 0.5794 - loss: 1.1573\n",
      "Epoch 33/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.5828 - loss: 1.1587\n",
      "Epoch 34/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 944us/step - accuracy: 0.5828 - loss: 1.1481\n",
      "Epoch 35/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 923us/step - accuracy: 0.5807 - loss: 1.1625\n",
      "Epoch 36/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 983us/step - accuracy: 0.5803 - loss: 1.1642\n",
      "Epoch 37/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5788 - loss: 1.1555\n",
      "Epoch 38/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972us/step - accuracy: 0.5861 - loss: 1.1509\n",
      "Epoch 39/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 962us/step - accuracy: 0.5791 - loss: 1.1577\n",
      "Epoch 40/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 937us/step - accuracy: 0.5762 - loss: 1.1705\n",
      "Epoch 41/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 958us/step - accuracy: 0.5849 - loss: 1.1543\n",
      "Epoch 42/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 0.5828 - loss: 1.1419\n",
      "Epoch 43/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5874 - loss: 1.1478  \n",
      "Epoch 44/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 957us/step - accuracy: 0.5876 - loss: 1.1437\n",
      "Epoch 45/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 955us/step - accuracy: 0.5842 - loss: 1.1533\n",
      "Epoch 46/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 972us/step - accuracy: 0.5891 - loss: 1.1539\n",
      "Epoch 47/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 933us/step - accuracy: 0.5863 - loss: 1.1491\n",
      "Epoch 48/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 964us/step - accuracy: 0.5841 - loss: 1.1479\n",
      "Epoch 49/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 979us/step - accuracy: 0.5862 - loss: 1.1447\n",
      "Epoch 50/50\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - accuracy: 0.5825 - loss: 1.1565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x213ce544fd0>"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network_99.compile(loss = \"sparse_categorical_crossentropy\", \n",
    "                       optimizer = tf.keras.optimizers.Adam(0.001), \n",
    "                       metrics = [\"accuracy\"])\n",
    "\n",
    "neural_network_99.fit(x_train_99, y_training, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "cff2beba-fa3f-4544-b208-b5d5b5d2b326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.5377 - loss: 1.2816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2842237949371338, 0.5382000207901001]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network_99.evaluate(x_test_99, y_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd83046-6d62-4506-af99-95d34c1b8d74",
   "metadata": {},
   "source": [
    "Training a Neural Network model with 3072 features and 50 epochs takes 176 seconds to excecute, a training accuracy of 51.2% was achieved and a testing score of 52%. Reducing the features to 658 resulted in a training execution time of 98 seconds for 50 epochs and a training and testing accuracy of 75.8% and 49.5% respectively. A model with 217 features and 50 epcchs resulted in a fitting execution time of 79 seconds and a training and testing accuracy of 64.9% and 53.1% respectively. 99 Features has the shortest fitting execution time of 79 seconds, the accuracy of both the training and testing sets are 58.3% and 53.8%. It is expected for neural network models to take longer to train since these models are more complex and have many more parameters compared to Logistic Regression when comparing models with the same amount of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69166120-0596-439b-9178-2301c4f9138c",
   "metadata": {},
   "source": [
    "**Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e3321-2091-4e47-8f55-869738d94ba4",
   "metadata": {},
   "source": [
    "Table 1: Outcome of different classifiers on CIFAR-10 original dataset\n",
    "\n",
    "| **Classifier** | **Accuracy [%]** |\n",
    "|--------------|--------------|\n",
    "| LR       |   41.4    |\n",
    "| NN       |   52.0    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c6832-6320-4ae2-98f4-8504bf195fca",
   "metadata": {},
   "source": [
    "Table 2: Outcome of different classifiers on CIFAR-10 reduced dataset\n",
    "\n",
    "| **Classifier** | **Accuracy with 658 features [%]** | **Accuracy with 217 features [%]** | **Accuracy with 99 features [%]** |\r\n",
    "|--------------|--------------|--------------|--------------|\r\n",
    "| PCA + LR      | 40.8        | 40.6        | 40.2        |\r\n",
    "| Fusion-Net    | 49.5        | 53.1        | 53.8        |  |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f601133a-7084-470a-9033-7612db59d65e",
   "metadata": {},
   "source": [
    "Table 3: Outcome of different classifiers on CIFAR-10 reduced dataset\n",
    "\n",
    "|**No. of features** | **Total number of parameters** |\n",
    "|--------------|--------------|\n",
    "|Original dataset (3072)       |402,250      |\n",
    "|658 features       |93,258    |\n",
    "|217 features        |36,810 |\n",
    "|99 features      |21,706     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b213e38-27df-40e2-9162-842e76941c16",
   "metadata": {},
   "source": [
    "The accuracy results in Table 1 and 2 show that Fusion-Net outperformed Logistic Regression which also used the reduced datasets. Neural Networks are more capable than Logistic Regression when it comes to handling non-linearity and high-dimensional data. The Fusion-Net has more tunable parameters than Logistic Regression which makes it more flexible hence in this image classification problem, Fusion-Net performed better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f76a7b-6e8d-45f2-b587-d4d29f12a2fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
